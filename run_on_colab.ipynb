{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3625d056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d1f9adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'afm-morphology-transfer-learning'...\n",
      "remote: Enumerating objects: 216, done.\u001b[K\n",
      "remote: Counting objects: 100% (216/216), done.\u001b[K\n",
      "remote: Compressing objects: 100% (172/172), done.\u001b[K\n",
      "remote: Total 216 (delta 40), reused 199 (delta 25), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (216/216), 28.77 MiB | 24.70 MiB/s, done.\n",
      "Resolving deltas: 100% (40/40), done.\n",
      "/content/afm-morphology-transfer-learning\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.0.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.9.0+cpu)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (0.24.0+cpu)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (3.15.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (4.67.1)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (2.19.0)\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (0.23.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (3.10.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (2025.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->-r requirements.txt (line 3)) (11.3.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.76.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 6)) (3.10)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 6)) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 6)) (5.29.5)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 6)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 6)) (3.1.4)\n",
      "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb->-r requirements.txt (line 7)) (8.3.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->-r requirements.txt (line 7)) (3.1.45)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb->-r requirements.txt (line 7)) (4.5.1)\n",
      "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb->-r requirements.txt (line 7)) (2.12.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb->-r requirements.txt (line 7)) (6.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->-r requirements.txt (line 7)) (2.32.4)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->-r requirements.txt (line 7)) (2.47.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 8)) (2.9.0.post0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 7)) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 7)) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 7)) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 7)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 7)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 7)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 7)) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 6)) (3.0.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 7)) (5.0.2)\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/dbecerril/afm-morphology-transfer-learning.git\n",
    "%cd afm-morphology-transfer-learning\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382f55f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/content/afm-morphology-transfer-learning/scripts/train_autoencoder.py\", line 43, in <module>\n",
      "    from datasets.afm_h5_dataset import AFMPatchesH5Dataset, ChannelNorm\n",
      "ModuleNotFoundError: No module named 'datasets'\n"
     ]
    }
   ],
   "source": [
    "!python scripts/train_autoencoder.py --h5 /content/afm_patches.h5 --in-channels 2 --out-channels 1 --target-channel 0 --log-tb --log-dir logs --run-name test_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3562459c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/afm-morphology-transfer-learning'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5848fb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets.afm_h5_dataset import AFMPatchesH5Dataset\n",
    "from model.autoencoder_model import AFMUNetAutoencoder\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Paths\n",
    "h5_path = \"/content/afm-morphology-transfer-learning/datasets/afm_patches_256.h5\"\n",
    "ckpt_path = \"/content/afm-morphology-transfer-learning/checkpoints/ae_20251217_114719/ae_best.pth\"\n",
    "\n",
    "# Dataset\n",
    "# IMPORTANT: if patches/norm exists, do NOT apply ChannelNorm again\n",
    "ds = AFMPatchesH5Dataset(\n",
    "    h5_path,\n",
    "    norm=None,                 # <-- correct for Option A\n",
    "    aux_types=[\"PHASE\", \"FRICTION\"],\n",
    "    indices=None,\n",
    "    x_dataset=\"patches/norm\"   # <-- explicitly use normalized data\n",
    ")\n",
    "\n",
    "# Model (Option A)\n",
    "model = AFMUNetAutoencoder(in_channels=2, out_channels=1).to(device)\n",
    "ck = torch.load(ckpt_path, map_location=device)\n",
    "state = ck[\"model_state_dict\"] if isinstance(ck, dict) else ck\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def show_topo_recon(x, xhat, title=\"\"):\n",
    "    \"\"\"\n",
    "    x:    (2,H,W)   input  [topo, aux]\n",
    "    xhat: (1,H,W)   recon topo\n",
    "    \"\"\"\n",
    "    topo_in = x[0]\n",
    "    aux_in  = x[1]\n",
    "    topo_out = xhat[0]\n",
    "    resid = (topo_in - topo_out).abs()\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    axes[0].imshow(topo_in, cmap=\"gray\")\n",
    "    axes[0].set_title(\"Topo input\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].imshow(aux_in, cmap=\"gray\")\n",
    "    axes[1].set_title(\"Aux input (phase/friction)\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    axes[2].imshow(topo_out, cmap=\"gray\")\n",
    "    axes[2].set_title(\"Topo recon\")\n",
    "    axes[2].axis(\"off\")\n",
    "\n",
    "    im = axes[3].imshow(resid, cmap=\"inferno\")\n",
    "    axes[3].set_title(\"|Topo − Recon|\")\n",
    "    axes[3].axis(\"off\")\n",
    "    plt.colorbar(im, ax=axes[3])\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ---- Run on a sample ----\n",
    "idx = 0\n",
    "x = torch.from_numpy(ds[idx]).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    xhat = model(x)\n",
    "\n",
    "show_topo_recon(\n",
    "    x[0].cpu().numpy(),\n",
    "    xhat[0].cpu().numpy(),\n",
    "    title=f\"Sample {idx}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc109fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def show_random_triplets(\n",
    "    ds,\n",
    "    model,\n",
    "    n=5,\n",
    "    channel=0,\n",
    "    seed=None,\n",
    "):\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    indices = random.sample(range(len(ds)), n)\n",
    "\n",
    "    for idx in indices:\n",
    "        sample = ds[idx]\n",
    "        x = sample[0] if isinstance(sample, (tuple, list)) else sample\n",
    "        x = x.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            xhat = model(x.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "        show_triplet(\n",
    "            x.cpu(),\n",
    "            xhat.cpu(),\n",
    "            title=f\"Sample {idx}\",\n",
    "            channel=channel,\n",
    "        )\n",
    "\n",
    "# usage\n",
    "show_random_triplets(ds, model, n=3, channel=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d196dcdb",
   "metadata": {},
   "source": [
    "# Load a data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49627e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datasets.afm_h5_dataset import AFMPatchesH5Dataset, ChannelNorm\n",
    "\n",
    "#Load normalization stats\n",
    "stats_path = \"stats/channel_norm.json\"  # or from run folder\n",
    "with open(stats_path) as f:\n",
    "    stats = json.load(f)\n",
    "\n",
    "norm = ChannelNorm(\n",
    "    mean=torch.tensor(stats[\"mean\"], dtype=torch.float32),\n",
    "    std=torch.tensor(stats[\"std\"], dtype=torch.float32),\n",
    ")\n",
    "\n",
    "#load training indices\n",
    "split_path = \"splits/train.npy\"  # adjust if needed\n",
    "indices = np.load(split_path)\n",
    "\n",
    "# Creat dataset\n",
    "aux_types = [\"TOPO\", \"PHASE\"]  # ← example, MUST match training order\n",
    "\n",
    "h5_path = \"c:\\\\Users\\\\david\\\\OneDrive\\\\Documents\\\\ml_projects\\\\afm-morphology-transfer-learning\\\\datasets\\\\afm_patches_256.h5\"\n",
    "\n",
    "train_ds = AFMPatchesH5Dataset(\n",
    "    h5_path,\n",
    "    norm=norm,\n",
    "    aux_types=aux_types,\n",
    "    indices=indices,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=16,        # smaller is fine for inspection\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c471fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "xb = next(iter(train_loader))\n",
    "print(xb.shape)  # should be [B, C, H, W]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b6158c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mmodel\u001b[49m.to(device)\n\u001b[32m      3\u001b[39m model.eval()\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    xb = xb.to(device)\n",
    "    yb = model(xb)\n",
    "\n",
    "    per_ch_mse = ((yb - xb) ** 2).mean(dim=(0,2,3))\n",
    "    per_ch_mae = (yb - xb).abs().mean(dim=(0,2,3))\n",
    "\n",
    "print(\"Per-channel MSE:\", per_ch_mse.cpu().numpy())\n",
    "print(\"Per-channel MAE:\", per_ch_mae.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be59f431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ae_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
